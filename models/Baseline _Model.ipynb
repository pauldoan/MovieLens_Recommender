{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1 - Recommender system for movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start by reading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.session import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     1|      2|   3.5|\n",
      "|     1|     29|   3.5|\n",
      "|     1|     32|   3.5|\n",
      "|     1|     47|   3.5|\n",
      "|     1|     50|   3.5|\n",
      "|     1|    112|   3.5|\n",
      "|     1|    151|   4.0|\n",
      "|     1|    223|   4.0|\n",
      "|     1|    253|   4.0|\n",
      "|     1|    260|   4.0|\n",
      "|     1|    293|   4.0|\n",
      "|     1|    296|   4.0|\n",
      "|     1|    318|   4.0|\n",
      "|     1|    337|   3.5|\n",
      "|     1|    367|   3.5|\n",
      "|     1|    541|   4.0|\n",
      "|     1|    589|   3.5|\n",
      "|     1|    593|   3.5|\n",
      "|     1|    653|   3.0|\n",
      "|     1|    919|   3.5|\n",
      "+------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.csv(\"ratings.csv\", header='true').drop('timestamp')\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entries of our dataframes are strings, we need to convert them into **numeric** ones so that we can apply our algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType, IntegerType\n",
    "\n",
    "data = data.withColumn(\"movieId\", data[\"movieId\"].cast(IntegerType()))\n",
    "data = data.withColumn(\"userId\", data[\"userId\"].cast(IntegerType()))\n",
    "data = data.withColumn(\"rating\", data[\"rating\"].cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling the data\n",
    "\n",
    "Let us build our dataset for this homework:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('ratings.csv').drop('timestamp', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0       1        2     3.5\n",
       "1       1       29     3.5\n",
       "2       1       32     3.5\n",
       "3       1       47     3.5\n",
       "4       1       50     3.5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId     1005\n",
       "movieId    1005\n",
       "rating     1005\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = data['movieId'].value_counts()\n",
    "data = data[data['movieId'].isin(counts.index[counts > 5000])]\n",
    "data.groupby('movieId').nunique().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we selected the 1,005 movies that have more than 5,000 ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId     138476\n",
       "movieId    138476\n",
       "rating     138476\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('userId').nunique().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 138,476 distinct users in our dataset. Let us select randomly some of them to build our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([128053,   5194,  50065, ...,  90167,  70032,  49250])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "sample = data['userId'].unique()\n",
    "sample_users = np.random.choice(sample, 10000)\n",
    "sample_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>10</td>\n",
       "      <td>260</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>10</td>\n",
       "      <td>356</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999279</th>\n",
       "      <td>138484</td>\n",
       "      <td>733</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999280</th>\n",
       "      <td>138484</td>\n",
       "      <td>736</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999281</th>\n",
       "      <td>138484</td>\n",
       "      <td>748</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999282</th>\n",
       "      <td>138484</td>\n",
       "      <td>780</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999283</th>\n",
       "      <td>138484</td>\n",
       "      <td>802</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>890576 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          userId  movieId  rating\n",
       "922           10        1     4.0\n",
       "923           10       11     4.0\n",
       "924           10       25     4.0\n",
       "925           10      260     4.0\n",
       "926           10      356     3.0\n",
       "...          ...      ...     ...\n",
       "19999279  138484      733     3.0\n",
       "19999280  138484      736     4.0\n",
       "19999281  138484      748     3.0\n",
       "19999282  138484      780     5.0\n",
       "19999283  138484      802     5.0\n",
       "\n",
       "[890576 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = data.loc[data['userId'].isin(sample_users)]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId     1005\n",
       "movieId    1005\n",
       "rating     1005\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.groupby('movieId').nunique().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId     9672\n",
       "movieId    9672\n",
       "rating     9672\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.groupby('userId').nunique().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, our dataset contains 1,005 distinct movies and 9,675 users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now split our datset in a train set and a test set. We will use both of them for the rest of our study in this homework:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = spark.createDataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training, test) = dataset.randomSplit([0.8,0.2], seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712334 178242\n"
     ]
    }
   ],
   "source": [
    "print(training.count(), test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics\n",
    "\n",
    "We can make some statistics about our new set of movies to better understand it. Here is the number of ratings each movie has:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|movieId|count|\n",
      "+-------+-----+\n",
      "|    296| 4654|\n",
      "|    356| 4563|\n",
      "|    318| 4403|\n",
      "|    593| 4400|\n",
      "|    480| 4038|\n",
      "|    110| 3753|\n",
      "|    260| 3738|\n",
      "|    589| 3561|\n",
      "|   2571| 3532|\n",
      "|      1| 3437|\n",
      "|    527| 3416|\n",
      "|    457| 3365|\n",
      "|    150| 3256|\n",
      "|    780| 3252|\n",
      "|     50| 3221|\n",
      "|   1210| 3203|\n",
      "|     32| 3185|\n",
      "|    592| 3101|\n",
      "|   2858| 3099|\n",
      "|    608| 3031|\n",
      "+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stat = dataset.groupBy(\"movieId\").count().sort('count', ascending=False)\n",
    "stat.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|            count|\n",
      "+-------+-----------------+\n",
      "|  count|             1005|\n",
      "|   mean|886.1452736318408|\n",
      "| stddev|651.5892025154428|\n",
      "|    min|              326|\n",
      "|    max|             4654|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stat.describe('count').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the number of ratings with respect to the number of movies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x120b74150>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "panda_stat = stat.toPandas()\n",
    "\n",
    "bin_ = [i*500 for i in range(10)]\n",
    "\n",
    "panda_stat.hist(column='count', bins=bin_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the vast majority of the movies have less than 1,000 ratings and just a few of them have more ratings. This is the long tail effect: the popular movies (that represent a small proportion of the overall dataset) are far more rated than the other ones. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "\n",
    "In this section, we will define the metrics functions which we will use later to assess the performances of our models:\n",
    "- MAE\n",
    "- RMSE\n",
    "- precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAE and RMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "def RMSE(y_predicted, y):\n",
    "    rmse = np.sqrt(mean_squared_error(y, y_predicted))\n",
    "    return(\"RMSE = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us first create a function to transform our raw predictions into appropriate ones.\n",
    "def round_rating(x): \n",
    "    dec = x - int(x)\n",
    "    if (dec >= 0.25) and (dec < 0.75):\n",
    "        return int(x) + 0.5\n",
    "    else:\n",
    "        return int(x) + (dec > 0.5)\n",
    "\n",
    "# Precision function metric:\n",
    "def precision(y, y_predicted):\n",
    "    y_predicted = [round_rating(k) for k in y_predicted]       \n",
    "    TP = 0\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == y_predicted[i]:\n",
    "            TP += 1\n",
    "    return TP/len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since most collaborative filtering methods start off with a simple baseline model, we will begin by implementing the following model to our data:\n",
    "<br><br>\n",
    "$$r_{ui}=\\mu + \\beta_u + \\beta_i$$\n",
    "<br>\n",
    "with: \n",
    "* $\\mu$: global average rating\n",
    "* $\\beta_u$: user bias\n",
    "* $\\beta_i$: item bias\n",
    "<br><br>\n",
    "This non-personalized bias model predicts the ratings given by a user only by taking into account the user generosity and item popularity, rather than specific and personalized interests of users in items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us calculate $\\mu$ first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|            rating|\n",
      "+-------+------------------+\n",
      "|  count|            712334|\n",
      "|   mean| 3.639545494108101|\n",
      "| stddev|1.0158713154695678|\n",
      "|    min|               0.5|\n",
      "|    max|               5.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training.describe(\"rating\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 3.639545494108101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us compute the $\\beta_i$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_mean = training.groupby('movieId').mean(\"rating\")\n",
    "#item_mean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_bias = item_mean.toPandas()\n",
    "item_bias['item_bias'] = mu - item_bias['avg(rating)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|movieId|           item_bias|\n",
      "+-------+--------------------+\n",
      "|     29|-0.31661316977498855|\n",
      "|    474|-0.10794446573125649|\n",
      "|   2529|0.025175992641825573|\n",
      "|    541| -0.4731643380261916|\n",
      "|   5418| -0.2855591084023592|\n",
      "|   1258| -0.3343641632127712|\n",
      "|    293| -0.4674996495307502|\n",
      "|   1127|-0.01245041172608...|\n",
      "|   1371| 0.41932888760990616|\n",
      "|   8636| 0.06542918852087176|\n",
      "|   1409|  0.6291597374315434|\n",
      "|   2581|  0.5827887373513443|\n",
      "|   3704| 0.46820593024517265|\n",
      "|    222| 0.06043157005746824|\n",
      "|   2797| 0.05387133680473033|\n",
      "|   2944|-0.24862931308984226|\n",
      "|    367|  0.4957205853014308|\n",
      "|    442|   0.609795014261652|\n",
      "|    720|-0.44993996450487383|\n",
      "|   1175|   -0.40831344795739|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let us transform the pandas dataframe into a Spark one. \n",
    "# This operation is purely aesthetic - we found it looks better to show the results under this format.\n",
    "\n",
    "item_bias = spark.createDataFrame(item_bias).drop('avg(rating)')\n",
    "item_bias.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can compute the $\\beta_u$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mean = training.groupby('userId').mean(\"rating\")\n",
    "#user_mean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_bias = user_mean.toPandas()\n",
    "user_bias['user_bias'] = mu - user_bias['avg(rating)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|           user_bias|\n",
      "+------+--------------------+\n",
      "|  2509| -0.5912237366611297|\n",
      "|  9715|-0.23545450589189887|\n",
      "| 15663|-0.26954541498280804|\n",
      "| 15846|  0.2917194071515792|\n",
      "| 17043|-0.04650101751980573|\n",
      "| 18147| 0.11013372940221888|\n",
      "| 23116|  0.5681169226795295|\n",
      "| 26543| 0.11013372940221888|\n",
      "| 30025| -0.1786363240737172|\n",
      "| 30428|  0.7958700764470032|\n",
      "| 32954|-0.37327501871241164|\n",
      "| 33862|-0.02712117255856...|\n",
      "| 38543| -0.5709808216813723|\n",
      "| 42852| 0.23478358934619648|\n",
      "| 48280|  1.0581501452708917|\n",
      "| 50219| 0.09409094865355572|\n",
      "| 53509|-0.19598082168137276|\n",
      "| 53721|-0.09378783922523226|\n",
      "| 54039|-0.08045450589189906|\n",
      "| 72203| 0.24668835125095834|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let us transform the pandas dataframe into a Spark one. \n",
    "# This operation is purely aesthetic - we found it looks better to show the results under this format.\n",
    "\n",
    "user_bias = spark.createDataFrame(user_bias).drop('avg(rating)')\n",
    "user_bias.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, here is a function to predict the rating a user would give to an item - based on our baseline model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us re-transform our Spark dataframes into Pandas ones for easier computations. \n",
    "\n",
    "item_bias = item_bias.toPandas().set_index('movieId')\n",
    "user_bias = user_bias.toPandas().set_index('userId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_rating(userId, movieId):\n",
    "    if movieId not in item_bias.index:\n",
    "        return mu\n",
    "    elif userId not in user_bias.index:\n",
    "        return mu\n",
    "    else:\n",
    "        return mu + item_bias.loc[movieId, 'item_bias'] + user_bias.loc[userId, 'user_bias']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now assess how our baseline model performs on our test set. We will thus be able to compare this model to the other ones then. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>260</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>527</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>1250</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>1304</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0      10        1     4.0\n",
       "1      10      260     4.0\n",
       "2      10      527     5.0\n",
       "3      10     1250     4.0\n",
       "4      10     1304     3.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_test = test.toPandas()\n",
    "pd_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = []\n",
    "\n",
    "for i in range(len(pd_test.index)):\n",
    "    movieId = pd_test.iloc[i, 1]\n",
    "    userId = pd_test.iloc[i, 0]\n",
    "    y_predicted.append(baseline_rating(userId, movieId))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd_test['rating'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>baseline_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.082961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>260</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.794382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>527</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.678454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>1250</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.926363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>1304</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.940234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  baseline_rating\n",
       "0      10        1     4.0         3.082961\n",
       "1      10      260     4.0         2.794382\n",
       "2      10      527     5.0         2.678454\n",
       "3      10     1250     4.0         2.926363\n",
       "4      10     1304     3.0         2.940234"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_test['baseline_rating'] = y_predicted\n",
    "pd_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|   baseline_rating|\n",
      "+-------+------------------+\n",
      "|  count|            178242|\n",
      "|   mean|3.6398968744318725|\n",
      "| stddev|0.6129913795236411|\n",
      "|    min|1.6503683761614605|\n",
      "|    max| 7.643023206711027|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stat_1 = spark.createDataFrame(pd_test)\n",
    "stat_1.describe('baseline_rating').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  1.1506927386312016 \n",
      " RMSE = 1.4410602572570943 \n",
      "precision:  0.1298291087398032\n"
     ]
    }
   ],
   "source": [
    "mae_baseline_1 = mean_absolute_error(y, y_predicted)\n",
    "rmse_baseline_1 = RMSE(y, y_predicted)\n",
    "precision_baseline_1 = precision(y, y_predicted)\n",
    "\n",
    "print('MAE: ', mae_baseline_1, '\\n', rmse_baseline_1, '\\nprecision: ', precision_baseline_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can observe the RMSE for this baseline model is quite bad.**\n",
    "As stated previously, the ratings are done by taking into account the user generosity and item popularity, rather than specific and personalized interests of users in items. That is why the predictions are not accurate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessment of another baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another simpler baseline model would be to return the global average ratings for all the movies and users as following:\n",
    "<br><br>\n",
    "$$r_{ui}=\\mu $$\n",
    "<br>\n",
    "with $\\mu$, the global average rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = [mu for i in range(len(y))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.8195743288512253 \n",
      " RMSE = 1.0181109771997578 \n",
      "precision:  0.1013453619236768\n"
     ]
    }
   ],
   "source": [
    "# Assessment of this baseline model on our test set:\n",
    "\n",
    "mae_baseline_2 = mean_absolute_error(y, y_predicted)\n",
    "rmse_baseline_2 = RMSE(y, y_predicted)\n",
    "precision_baseline_2 = precision(y, y_predicted)\n",
    "\n",
    "print('MAE: ', mae_baseline_2, '\\n', rmse_baseline_2, '\\nprecision: ', precision_baseline_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that this simpler baseline actually returns better results than the previous one. **The precision is a bit lower, but the RMSE is much lower which means that, in general, our predictions are closer to the real ones**. <br>  We will thus use this model for our homework to compare the performances of the personalized models we are going to build later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
